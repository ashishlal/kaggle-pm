{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/watts/Software/xgboost/python-package') # for xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "  \n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "import copy\n",
    "\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import log_loss, confusion_matrix, f1_score, accuracy_score\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 4.572507552870091, 2: 6.407630522088353, 3: 37.427083333333336, 4: 3.912117177097204, 5: 12.816479400749063, 6: 11.42087542087542, 7: 2.5, 8: 174.66666666666666, 9: 84.79069767441861}\n"
     ]
    }
   ],
   "source": [
    "df_train = np.load('../cache/train_stage2_fe2.npy')\n",
    "df_test = np.load('../cache/test_stage2_fe2.npy')\n",
    "df = pd.read_csv('../cache/stage2_labels.csv')\n",
    "y = df['y'].values\n",
    "\n",
    "df = pd.read_csv('../cache/stage2_test_id.csv')\n",
    "pid = df.ID.values\n",
    "\n",
    "wts_per_class = np.load('../cache/stage2_train_weights_per_class.npy')\n",
    "wts_per_class = wts_per_class.tolist()\n",
    "print(wts_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.572507552870091, 6.407630522088353, 37.427083333333336, 3.912117177097204, 12.816479400749063, 11.42087542087542, 2.5, 174.66666666666666, 84.79069767441861]\n"
     ]
    }
   ],
   "source": [
    "wts_per_class2 = []\n",
    "for i in range(len(wts_per_class)):\n",
    "    wts_per_class2.append(wts_per_class[i+1])\n",
    "\n",
    "print(wts_per_class2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = y-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = np.array([wts_per_class2[j] for j in y], )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 4.572507552870091, 1: 6.407630522088353, 2: 37.427083333333336, 3: 3.912117177097204, 4: 12.816479400749063, 5: 11.42087542087542, 6: 2.5, 7: 174.66666666666666, 8: 84.79069767441861}\n"
     ]
    }
   ],
   "source": [
    "wts_per_class3 = {}\n",
    "for i in range(len(wts_per_class)):\n",
    "    wts_per_class3[i]=wts_per_class[i+1]\n",
    "\n",
    "print(wts_per_class3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = xgb.XGBClassifier(objective='multi:softprob',\n",
    "                         num_class= 9,\n",
    "                         eval_metric= 'logloss',\n",
    "                         colsample_bytree= 0.8,\n",
    "                         learning_rate= 0.03,\n",
    "                         max_depth= 6,\n",
    "                         min_child_weight= 5,\n",
    "                         missing= -999,\n",
    "                         nthread= 4,\n",
    "                         seed= 1337,\n",
    "                         subsample= 0.8)\n",
    "\n",
    "clf2 = RandomForestClassifier(random_state=0, max_features='auto', n_estimators=700, class_weight='balanced')\n",
    "clf3 = LGBMClassifier(learning_rate=0.03, max_bin= 100, max_depth= 7, n_estimators= 200, num_leaves= 150, \n",
    "                      class_weight='balanced')\n",
    "clf4 = MLPClassifier(alpha=0.001, learning_rate_init=0.1, max_iter=50, power_t=0.1, \n",
    "          random_state=1337, solver='adam')\n",
    "clf5 = CalibratedClassifierCV(OneVsOneClassifier(svm.SVC(probability=True, C=0.01, class_weight='balanced')))\n",
    "clf6 = OneVsRestClassifier(CalibratedClassifierCV(LinearSVC(class_weight='balanced')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(class_weight = wts_per_class3)\n",
    "\n",
    "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3, clf4, clf5, clf6], use_probas=True,\n",
    "                          meta_classifier=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validation:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss: -0.99 (+/- 0.03) [xgb]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss: -0.93 (+/- 0.05) [RF]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss: -0.89 (+/- 0.03) [LGBM]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss: -1.83 (+/- 0.00) [mlp]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss: -1.83 (+/- 0.00) [ovo]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss: -1.80 (+/- 0.01) [ovr]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/scorer.py:137: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss: -3.41 (+/- 0.20) [StackingClassifier]\n"
     ]
    }
   ],
   "source": [
    "# sclf = StackingClassifier(classifiers=[clf1, clf2, clf3, clf4, clf5, clf6], \n",
    "#                           meta_classifier=lr)\n",
    "\n",
    "print('5-fold cross validation:\\n')\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, clf4, clf5, clf6, sclf],  \n",
    "                      ['xgb',\n",
    "                       'RF',\n",
    "                       'LGBM',\n",
    "                       'mlp',\n",
    "                       'ovo',\n",
    "                       'ovr',\n",
    "                       'StackingClassifier']):\n",
    "\n",
    "    scores = model_selection.cross_val_score(clf, df_train, y, cv=StratifiedKFold(y, 5, True), scoring='log_loss')\n",
    "    print(\"log_loss: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3689, 4689)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(average_probas=False,\n",
       "          classifiers=[XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='logloss', gamma=0,\n",
       "       learning_rate=0.03, max_delta_step=0, max_depth=6,\n",
       "       min_child_weight=5, missing=-999, n_estimators=100, n_jobs=1,\n",
       "       nthread=4, num_class=9,...m_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "            cv=3, method='sigmoid'),\n",
       "          n_jobs=1)],\n",
       "          meta_classifier=LogisticRegression(C=1.0,\n",
       "          class_weight={0: 4.572507552870091, 1: 6.407630522088353, 2: 37.427083333333336, 3: 3.912117177097204, 4: 12.816479400749063, 5: 11.42087542087542, 6: 2.5, 7: 174.66666666666666, 8: 84.79069767441861},\n",
       "          dual=False, fit_intercept=True, intercept_scaling=1,\n",
       "          max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2',\n",
       "          random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "          warm_start=False),\n",
       "          use_features_in_secondary=False, use_probas=False, verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sclf.fit(df_train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z = df_test\n",
    "X = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3689, 4689)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(986, 4689)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proba = sclf.predict_proba(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(986, 9)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proba = proba.clip(min=0.05, max=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(proba, \n",
    "                  columns=['class1', 'class2', 'class3', 'class4', 'class5', 'class6', 'class7', 'class8', 'class9'])\n",
    "df['ID'] = pid\n",
    "df.to_csv('../submissions/sub_stage2_stacked_clf.csv', index=False)\n",
    "# 2.59964 on stage2 private LB, 2.15842 on stage2 public LB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use XGB as meta classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = xgb.XGBClassifier(booster='gbtree', objective='binary:logistic', eval_metric='error', eta=0.03,\n",
    "                      gamma=0, max_depth=6, min_child_weight=1, max_delta_step=0, subsample=0.8,\n",
    "                      colsample_by_tree=0.8, silent=1, seed = 0)\n",
    "sclf2 = StackingClassifier(classifiers=[clf1, clf2, clf3, clf4, clf5, clf6], use_probas=True,\n",
    "                          meta_classifier=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(average_probas=False,\n",
       "          classifiers=[XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='logloss', gamma=0,\n",
       "       learning_rate=0.03, max_delta_step=0, max_depth=6,\n",
       "       min_child_weight=5, missing=-999, n_estimators=100, n_jobs=1,\n",
       "       nthread=4, num_class=9,...m_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "            cv=3, method='sigmoid'),\n",
       "          n_jobs=1)],\n",
       "          meta_classifier=XGBClassifier(base_score=0.5, booster='gbtree', colsample_by_tree=0.8,\n",
       "       colsample_bylevel=1, colsample_bytree=1, eta=0.03,\n",
       "       eval_metric='error', gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=0, silent=1,\n",
       "       subsample=0.8),\n",
       "          use_features_in_secondary=False, use_probas=True, verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sclf2.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proba2 = sclf2.predict_proba(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proba2 = proba2.clip(min=0.05, max=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(proba2, \n",
    "                  columns=['class1', 'class2', 'class3', 'class4', 'class5', 'class6', 'class7', 'class8', 'class9'])\n",
    "\n",
    "df['ID'] = pid\n",
    "df.to_csv('../submissions/sub_stage2_stacked_clf2.csv', index=False)\n",
    "# 2.20186, stage2 private LB, 2.10209 stage2 public LB (with XGB, RF, LGBM, MLP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find ensemble weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = np.load('../cache/train_stage2_x1.npy')\n",
    "x2 = np.load('../cache/train_stage2_x2.npy')\n",
    "y1 = np.load('../cache/train_stage2_y1.npy')\n",
    "y2 = np.load('../cache/train_stage2_y2.npy')\n",
    "\n",
    "# w1 = np.array([wts_per_class[j] for j in y1], )\n",
    "# w2 = np.array([wts_per_class[j] for j in y2], )\n",
    "\n",
    "w1 = np.load('../cache/stage2_train_weights_per_class.npy').tolist()\n",
    "w2 = np.load('../cache/stage2_train_weights_per_class.npy').tolist()\n",
    "\n",
    "w1_p = np.array([w1[j] for j in y1], )\n",
    "w2_p = np.array([w2[j] for j in y2], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf1 = xgb.XGBClassifier(objective='multi:softprob',\n",
    "                         num_class= 9,\n",
    "                         eval_metric= 'logloss',\n",
    "                         colsample_bytree= 0.8,\n",
    "                         learning_rate= 0.03,\n",
    "                         max_depth= 6,\n",
    "                         min_child_weight= 5,\n",
    "                         missing= -999,\n",
    "                         nthread= 4,\n",
    "                         seed= 1337,\n",
    "                         subsample= 0.8)\n",
    "\n",
    "clf2 = RandomForestClassifier(random_state=0, max_features='auto', n_estimators=700, class_weight='balanced')\n",
    "clf3 = LGBMClassifier(learning_rate=0.03, max_bin= 100, max_depth= 7, n_estimators= 200, num_leaves= 150, \n",
    "                      class_weight='balanced')\n",
    "clf4 = MLPClassifier(alpha=0.001, learning_rate_init=0.1, max_iter=50, power_t=0.1, \n",
    "          random_state=1337, solver='adam')\n",
    "clf5 = CalibratedClassifierCV(OneVsOneClassifier(svm.SVC(probability=True, C=0.01, class_weight='balanced')))\n",
    "clf6 = OneVsRestClassifier(CalibratedClassifierCV(LinearSVC(class_weight='balanced')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=CalibratedClassifierCV(base_estimator=LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "            cv=3, method='sigmoid'),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(x1, y1)\n",
    "clf2.fit(x1, y1)\n",
    "clf3.fit(x1, y1)\n",
    "clf4.fit(x1, y1)\n",
    "clf5.fit(x1, y1)\n",
    "clf6.fit(x1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfs = [clf1, clf2, clf3, clf4, clf5, clf6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for clf in clfs:\n",
    "    predictions.append(clf.predict_proba(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "starting_values = [0.5]*len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#adding constraints  and a different solver \n",
    "#https://kaggle2.blob.core.windows.net/forum-message-attachments/75655/2393/otto%20model%20weights.pdf?sv=2012-02-12&se=2015-05-03T21%3A22%3A17Z&sr=b&sp=r&sig=rkeA7EJC%2BiQ%2FJ%2BcMpcA4lYQLFh6ubNqs2XAkGtFsAv0%3D\n",
    "cons = ({'type':'eq','fun':lambda w: 1-sum(w)})\n",
    "#our weights are bound between 0 and 1\n",
    "bounds = [(0,1)]*len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_loss_func(weights):\n",
    "    ''' scipy minimize will pass the weights as a numpy array '''\n",
    "    final_prediction = 0\n",
    "    for weight, prediction in zip(weights, predictions):\n",
    "            final_prediction += weight*prediction\n",
    "\n",
    "    return log_loss(y2, final_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensamble Score: 0.8806840766897692\n",
      "Best Weights: [  8.19207423e-02   2.58625200e-01   6.59454057e-01   0.00000000e+00\n",
      "   1.94758402e-20   5.81090600e-17]\n"
     ]
    }
   ],
   "source": [
    "res = minimize(log_loss_func, starting_values, method='SLSQP', bounds=bounds, constraints=cons)\n",
    "\n",
    "print('Ensamble Score: {best_score}'.format(best_score=res['fun']))\n",
    "print('Best Weights: {weights}'.format(weights=res['x']))\n",
    "\n",
    "# Ensamble Score: 0.8446244568258605 (which using xgb, rf, lgbm, mlp)\n",
    "# Best Weights: [ 0.26833125  0.15014477  0.58152399  0.        ]\n",
    "\n",
    "# Ensamble Score: 0.8806840766897692 (which using xgb, rf, lgbm, mlp, ovo, ovr)\n",
    "# Best Weights: [  8.19207423e-02   2.58625200e-01   6.59454057e-01   0.00000000e+00\n",
    "#    1.94758402e-20   5.81090600e-17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = [ 8.19207423e-02,   2.58625200e-01,   6.59454057e-01,   0.00000000e+00, 1.94758402e-20,   5.81090600e-17]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first try with caclulated weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3, clf4, clf5, clf6], \n",
    "                              weights=w, voting='soft',\n",
    "                              refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EnsembleVoteClassifier(clfs=[XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='logloss', gamma=0,\n",
       "       learning_rate=0.03, max_delta_step=0, max_depth=6,\n",
       "       min_child_weight=5, missing=-999, n_estimators=100, n_jobs=1,\n",
       "       nthread=4, num_class=9, object...m_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "            cv=3, method='sigmoid'),\n",
       "          n_jobs=1)],\n",
       "            refit=True, verbose=0, voting='soft',\n",
       "            weights=[0.0819207423, 0.2586252, 0.659454057, 0.0, 1.94758402e-20, 5.810906e-17])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.981837896449\n"
     ]
    }
   ],
   "source": [
    "print('accuracy:', np.mean(y == eclf.predict(X)))\n",
    "# EnsembleVoteClassifier(clfs=[XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "#        colsample_bytree=0.7, eval_metric='logloss', gamma=0,\n",
    "#        learning_rate=0.03, max_delta_step=0, max_depth=6,\n",
    "#        min_child_weight=11, missing=-999, n_estimators=100, n_jobs=1,\n",
    "#        nthread=4, num_class=9, objec...stimators=1000, n_jobs=1,\n",
    "#             oob_score=False, random_state=1, verbose=0, warm_start=False)],\n",
    "#             refit=True, verbose=0, voting='hard', weights=[1, 1])\n",
    "# accuracy: 0.934128490106 with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proba3 = eclf.predict_proba(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proba3 = proba3.clip(min=0.05, max=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(proba3, \n",
    "                  columns=['class1', 'class2', 'class3', 'class4', 'class5', 'class6', \n",
    "                           'class7', 'class8', 'class9'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['ID'] =pid\n",
    "df.to_csv('../submissions/sub_stage2_ensemble_clf_xgb_RF_LGBM_MLP_OVO_OVR.csv', index=False)\n",
    "# 2.50012 on stage2 private LB, 1.69519 on stage2 public LB (xgb + rf + lgbm + mlp)\n",
    "# 2.51517 on stage2 private LB. 1.68053 on stage2 public LB (xgb+rf+lgbm+ovo+ovr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.to_csv('../submissions/sub_stage2_ensemble_clf.csv', index=False) #xgb + rf\n",
    "# 2.39469 on stage2 private LB, 1.58242 on public LB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now with weights [1,1,1,1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eclf2 = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3, clf4, clf5, clf6], weights=[1,1,1,1,1,1], \n",
    "                              refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EnsembleVoteClassifier(clfs=[XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='logloss', gamma=0,\n",
       "       learning_rate=0.03, max_delta_step=0, max_depth=6,\n",
       "       min_child_weight=5, missing=-999, n_estimators=100, n_jobs=1,\n",
       "       nthread=4, num_class=9, object...m_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "            cv=3, method='sigmoid'),\n",
       "          n_jobs=1)],\n",
       "            refit=True, verbose=0, voting='hard',\n",
       "            weights=[1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proba4 = eclf2.predict_proba(Z)\n",
    "proba4 = proba4.clip(min=0.05, max=0.95)\n",
    "\n",
    "df = pd.DataFrame(proba4, \n",
    "                  columns=['class1', 'class2', 'class3', 'class4', 'class5', \n",
    "                           'class6', 'class7', 'class8', 'class9'])\n",
    "\n",
    "df['ID'] =pid\n",
    "df.to_csv('../submissions/sub_stage2_ensemble_clf_xgb_RF_LGBM_MLP_OVO_OVR_wt_111111.csv', index=False)\n",
    "# 2.34903 on stage2 private LB, 1.74848 on stage1 public LB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now at level 3 take a simple averge of all the submissions (stacking with lr, stacking with xgb, \n",
    "# ensemble with wts and ensemble with equal wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = (proba + proba2 + proba3 + proba4)/4\n",
    "pred = pred.clip(min=0.05, max=0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pred, \n",
    "                  columns=['class1', 'class2', 'class3', 'class4', 'class5', \n",
    "                           'class6', 'class7', 'class8', 'class9'])\n",
    "\n",
    "df['ID'] =pid\n",
    "df.to_csv('../submissions/sub_stage2_final_avg.csv', index=False)\n",
    "# scores 2.29762 at stage2 private LB and 1.82645 stage2 public LB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
