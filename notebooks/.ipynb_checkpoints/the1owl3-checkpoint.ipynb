{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from https://www.kaggle.com/the1owl/redefining-treatment-0-57456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/lda.py:6: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/learning_curve.py:23: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/qda.py:6: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import *\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/training_variants')\n",
    "test = pd.read_csv('../data/test_variants')\n",
    "trainx = pd.read_csv('../data/training_text', sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n",
    "testx = pd.read_csv('../data/test_text', sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, trainx, how='left', on='ID').fillna('')\n",
    "y = train['Class'].values\n",
    "train = train.drop(['Class'], axis=1)\n",
    "\n",
    "test = pd.merge(test, testx, how='left', on='ID').fillna('')\n",
    "pid = test['ID'].values\n",
    "\n",
    "df_all = pd.concat((train, test), axis=0, ignore_index=True)\n",
    "df_all['Gene_Share'] = df_all.apply(lambda r: sum([1 for w in r['Gene'].split(' ') if w in r['Text'].split(' ')]), axis=1)\n",
    "df_all['Variation_Share'] = df_all.apply(lambda r: sum([1 for w in r['Variation'].split(' ') if w in r['Text'].split(' ')]), axis=1)\n",
    "\n",
    "#commented for Kaggle Limits\n",
    "for i in range(56):\n",
    "    df_all['Gene_'+str(i)] = df_all['Gene'].map(lambda x: str(x[i]) if len(x)>i else '')\n",
    "    df_all['Variation'+str(i)] = df_all['Variation'].map(lambda x: str(x[i]) if len(x)>i else '')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3260\n",
      "3091\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "gen_var_lst = sorted(list(train.Gene.unique()) + list(train.Variation.unique()))\n",
    "print(len(gen_var_lst))\n",
    "gen_var_lst = [x for x in gen_var_lst if len(x.split(' '))==1]\n",
    "print(len(gen_var_lst))\n",
    "i_ = 0\n",
    "#commented for Kaggle Limits\n",
    "for gen_var_lst_itm in gen_var_lst:\n",
    "    if i_ % 100 == 0: print(i_)\n",
    "    df_all['GV_'+str(gen_var_lst_itm)] = df_all['Text'].map(lambda x: str(x).count(str(gen_var_lst_itm)))\n",
    "    i_ += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for c in df_all.columns:\n",
    "    if df_all[c].dtype == 'object':\n",
    "        if c in ['Gene','Variation']:\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            df_all[c+'_lbl_enc'] = lbl.fit_transform(df_all[c].values)  \n",
    "            df_all[c+'_len'] = df_all[c].map(lambda x: len(str(x)))\n",
    "            df_all[c+'_words'] = df_all[c].map(lambda x: len(str(x).split(' ')))\n",
    "        elif c != 'Text':\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            df_all[c] = lbl.fit_transform(df_all[c].values)\n",
    "        if c=='Text': \n",
    "            df_all[c+'_len'] = df_all[c].map(lambda x: len(str(x)))\n",
    "            df_all[c+'_words'] = df_all[c].map(lambda x: len(str(x).split(' '))) \n",
    "\n",
    "train = df_all.iloc[:len(train)]\n",
    "test = df_all.iloc[len(train):]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class cust_regression_vals(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin):\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, x):\n",
    "        x = x.drop(['Gene', 'Variation','ID','Text'],axis=1).values\n",
    "        return x\n",
    "\n",
    "class cust_txt_col(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, x):\n",
    "        return x[self.key].apply(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Pipeline...')\n",
    "# fp = pipeline.Pipeline([\n",
    "#     ('union', pipeline.FeatureUnion(\n",
    "#         n_jobs = -1,\n",
    "#         transformer_list = [\n",
    "#             ('standard', cust_regression_vals()),\n",
    "#             ('pi1', pipeline.Pipeline([('Gene', cust_txt_col('Gene')), ('count_Gene', feature_extraction.text.CountVectorizer(analyzer=u'char', ngram_range=(1, 8))), ('tsvd1', decomposition.TruncatedSVD(n_components=20, n_iter=25, random_state=12))])),\n",
    "#             ('pi2', pipeline.Pipeline([('Variation', cust_txt_col('Variation')), ('count_Variation', feature_extraction.text.CountVectorizer(analyzer=u'char', ngram_range=(1, 8))), ('tsvd2', decomposition.TruncatedSVD(n_components=20, n_iter=25, random_state=12))])),\n",
    "#             #commented for Kaggle Limits\n",
    "#             #('pi3', pipeline.Pipeline([('Text', cust_txt_col('Text')), ('tfidf_Text', feature_extraction.text.TfidfVectorizer(ngram_range=(1, 2))), ('tsvd3', decomposition.TruncatedSVD(n_components=50, n_iter=25, random_state=12))]))\n",
    "#         ])\n",
    "#     )])\n",
    "\n",
    "# train = fp.fit_transform(train); print(train.shape)\n",
    "# test = fp.transform(test); print(test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline...\n",
      "(3321, 3553)\n",
      "(5668, 3553)\n"
     ]
    }
   ],
   "source": [
    "print('Pipeline...')\n",
    "fp = pipeline.Pipeline([\n",
    "    ('union', pipeline.FeatureUnion(\n",
    "        n_jobs = -1,\n",
    "        transformer_list = [\n",
    "            ('standard', cust_regression_vals()),\n",
    "            ('pi1', pipeline.Pipeline([('Gene', cust_txt_col('Gene')), \n",
    "                                       ('count_Gene', feature_extraction.text.CountVectorizer(analyzer=u'char', ngram_range=(1, 8))), \n",
    "                                       ('tsvd1', decomposition.TruncatedSVD(n_components=20, n_iter=25, random_state=12))])),\n",
    "            ('pi2', pipeline.Pipeline([('Variation', cust_txt_col('Variation')), \n",
    "                                       ('count_Variation', feature_extraction.text.CountVectorizer(analyzer=u'char', ngram_range=(1, 8))), \n",
    "                                       ('tsvd2', decomposition.TruncatedSVD(n_components=20, n_iter=25, random_state=12))])),\n",
    "            #commented for Kaggle Limits\n",
    "            ('pi3', pipeline.Pipeline([('Text', cust_txt_col('Text')), \n",
    "                                       ('hv', feature_extraction.text.HashingVectorizer(decode_error='ignore', n_features=2 ** 16, non_negative=True, ngram_range=(1, 3))),\n",
    "                                       ('tfidf_Text', feature_extraction.text.TfidfTransformer()), \n",
    "                                       ('tsvd3', decomposition.TruncatedSVD(n_components=300, n_iter=25, random_state=12))]))\n",
    "\n",
    "        \n",
    "        ])\n",
    "    )])\n",
    "\n",
    "tr = train\n",
    "te = test\n",
    "\n",
    "train = fp.fit_transform(train)\n",
    "print (train.shape)\n",
    "\n",
    "test_t = np.empty([0, train.shape[1]])\n",
    "step = 200\n",
    "for i in range(0, len(test), step):\n",
    "    step_end = i+step\n",
    "    step_end = step_end if step_end < len(test) else len(test)\n",
    "    _test = fp.transform(test.iloc[i:step_end])\n",
    "    test_t = np.vstack((test_t, _test))\n",
    "test = test_t\n",
    "print (test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.14016\tvalid-mlogloss:2.1497\n",
      "Multiple eval metrics have been passed: 'valid-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-mlogloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-mlogloss:1.07244\tvalid-mlogloss:1.27303\n",
      "[100]\ttrain-mlogloss:0.756886\tvalid-mlogloss:1.07319\n",
      "[150]\ttrain-mlogloss:0.584833\tvalid-mlogloss:0.996665\n",
      "[200]\ttrain-mlogloss:0.47126\tvalid-mlogloss:0.964943\n",
      "[250]\ttrain-mlogloss:0.38606\tvalid-mlogloss:0.945866\n",
      "[300]\ttrain-mlogloss:0.319656\tvalid-mlogloss:0.940504\n",
      "[350]\ttrain-mlogloss:0.269995\tvalid-mlogloss:0.940197\n",
      "[400]\ttrain-mlogloss:0.229927\tvalid-mlogloss:0.942933\n",
      "Stopping. Best iteration:\n",
      "[341]\ttrain-mlogloss:0.277925\tvalid-mlogloss:0.939538\n",
      "\n",
      "0.939538037788\n",
      "[0]\ttrain-mlogloss:2.14053\tvalid-mlogloss:2.15002\n",
      "Multiple eval metrics have been passed: 'valid-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-mlogloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-mlogloss:1.08225\tvalid-mlogloss:1.29185\n",
      "[100]\ttrain-mlogloss:0.757655\tvalid-mlogloss:1.08539\n",
      "[150]\ttrain-mlogloss:0.581267\tvalid-mlogloss:1.00986\n",
      "[200]\ttrain-mlogloss:0.469217\tvalid-mlogloss:0.978353\n",
      "[250]\ttrain-mlogloss:0.387681\tvalid-mlogloss:0.96558\n",
      "[300]\ttrain-mlogloss:0.325046\tvalid-mlogloss:0.96035\n",
      "[350]\ttrain-mlogloss:0.274784\tvalid-mlogloss:0.958251\n",
      "[400]\ttrain-mlogloss:0.234019\tvalid-mlogloss:0.961202\n",
      "[450]\ttrain-mlogloss:0.199635\tvalid-mlogloss:0.966195\n",
      "Stopping. Best iteration:\n",
      "[353]\ttrain-mlogloss:0.27212\tvalid-mlogloss:0.957964\n",
      "\n",
      "0.957963834268\n",
      "[0]\ttrain-mlogloss:2.14245\tvalid-mlogloss:2.1487\n",
      "Multiple eval metrics have been passed: 'valid-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-mlogloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-mlogloss:1.08501\tvalid-mlogloss:1.24313\n",
      "[100]\ttrain-mlogloss:0.766594\tvalid-mlogloss:1.03321\n",
      "[150]\ttrain-mlogloss:0.589366\tvalid-mlogloss:0.952641\n",
      "[200]\ttrain-mlogloss:0.476733\tvalid-mlogloss:0.915764\n",
      "[250]\ttrain-mlogloss:0.394833\tvalid-mlogloss:0.896855\n",
      "[300]\ttrain-mlogloss:0.330155\tvalid-mlogloss:0.886451\n",
      "[350]\ttrain-mlogloss:0.27813\tvalid-mlogloss:0.883361\n",
      "[400]\ttrain-mlogloss:0.234347\tvalid-mlogloss:0.887874\n",
      "[450]\ttrain-mlogloss:0.197947\tvalid-mlogloss:0.894902\n",
      "Stopping. Best iteration:\n",
      "[354]\ttrain-mlogloss:0.274334\tvalid-mlogloss:0.882643\n",
      "\n",
      "0.88264322306\n",
      "[0]\ttrain-mlogloss:2.14046\tvalid-mlogloss:2.14866\n",
      "Multiple eval metrics have been passed: 'valid-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-mlogloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-mlogloss:1.07374\tvalid-mlogloss:1.28985\n",
      "[100]\ttrain-mlogloss:0.753277\tvalid-mlogloss:1.08635\n",
      "[150]\ttrain-mlogloss:0.579504\tvalid-mlogloss:1.01408\n",
      "[200]\ttrain-mlogloss:0.469278\tvalid-mlogloss:0.977288\n",
      "[250]\ttrain-mlogloss:0.386593\tvalid-mlogloss:0.95992\n",
      "[300]\ttrain-mlogloss:0.321344\tvalid-mlogloss:0.951195\n",
      "[350]\ttrain-mlogloss:0.272141\tvalid-mlogloss:0.949567\n",
      "[400]\ttrain-mlogloss:0.228621\tvalid-mlogloss:0.951399\n",
      "Stopping. Best iteration:\n",
      "[343]\ttrain-mlogloss:0.27852\tvalid-mlogloss:0.948967\n",
      "\n",
      "0.948966910974\n",
      "[0]\ttrain-mlogloss:2.14161\tvalid-mlogloss:2.14615\n",
      "Multiple eval metrics have been passed: 'valid-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-mlogloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-mlogloss:1.08244\tvalid-mlogloss:1.2235\n",
      "[100]\ttrain-mlogloss:0.766337\tvalid-mlogloss:1.00949\n",
      "[150]\ttrain-mlogloss:0.590684\tvalid-mlogloss:0.927834\n",
      "[200]\ttrain-mlogloss:0.478184\tvalid-mlogloss:0.89025\n",
      "[250]\ttrain-mlogloss:0.394108\tvalid-mlogloss:0.869873\n",
      "[300]\ttrain-mlogloss:0.330455\tvalid-mlogloss:0.857923\n",
      "[350]\ttrain-mlogloss:0.27942\tvalid-mlogloss:0.847404\n",
      "[400]\ttrain-mlogloss:0.235839\tvalid-mlogloss:0.844188\n",
      "[450]\ttrain-mlogloss:0.199148\tvalid-mlogloss:0.842765\n",
      "[500]\ttrain-mlogloss:0.168376\tvalid-mlogloss:0.843885\n",
      "Stopping. Best iteration:\n",
      "[418]\ttrain-mlogloss:0.222074\tvalid-mlogloss:0.842358\n",
      "\n",
      "0.842358260635\n",
      "[0]\ttrain-mlogloss:2.14232\tvalid-mlogloss:2.14751\n",
      "Multiple eval metrics have been passed: 'valid-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-mlogloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-mlogloss:1.0794\tvalid-mlogloss:1.26778\n",
      "[100]\ttrain-mlogloss:0.75798\tvalid-mlogloss:1.0671\n",
      "[150]\ttrain-mlogloss:0.58972\tvalid-mlogloss:0.99518\n",
      "[200]\ttrain-mlogloss:0.476892\tvalid-mlogloss:0.966828\n",
      "[250]\ttrain-mlogloss:0.395365\tvalid-mlogloss:0.956566\n",
      "[300]\ttrain-mlogloss:0.330007\tvalid-mlogloss:0.958249\n",
      "[350]\ttrain-mlogloss:0.278527\tvalid-mlogloss:0.960928\n",
      "Stopping. Best iteration:\n",
      "[270]\ttrain-mlogloss:0.367823\tvalid-mlogloss:0.955988\n",
      "\n",
      "0.955988047934\n",
      "[0]\ttrain-mlogloss:2.14112\tvalid-mlogloss:2.14835\n",
      "Multiple eval metrics have been passed: 'valid-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-mlogloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-mlogloss:1.08485\tvalid-mlogloss:1.25147\n",
      "[100]\ttrain-mlogloss:0.766491\tvalid-mlogloss:1.03388\n",
      "[150]\ttrain-mlogloss:0.59184\tvalid-mlogloss:0.951298\n",
      "[200]\ttrain-mlogloss:0.478303\tvalid-mlogloss:0.916615\n",
      "[250]\ttrain-mlogloss:0.394296\tvalid-mlogloss:0.897901\n",
      "[300]\ttrain-mlogloss:0.329189\tvalid-mlogloss:0.889502\n",
      "[350]\ttrain-mlogloss:0.278215\tvalid-mlogloss:0.888331\n",
      "[400]\ttrain-mlogloss:0.235429\tvalid-mlogloss:0.884901\n",
      "[450]\ttrain-mlogloss:0.199956\tvalid-mlogloss:0.886\n",
      "[500]\ttrain-mlogloss:0.170756\tvalid-mlogloss:0.891382\n",
      "Stopping. Best iteration:\n",
      "[425]\ttrain-mlogloss:0.216838\tvalid-mlogloss:0.884592\n",
      "\n",
      "0.884592387431\n",
      "[0]\ttrain-mlogloss:2.14057\tvalid-mlogloss:2.14868\n",
      "Multiple eval metrics have been passed: 'valid-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-mlogloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-mlogloss:1.0769\tvalid-mlogloss:1.26805\n",
      "[100]\ttrain-mlogloss:0.756473\tvalid-mlogloss:1.05921\n",
      "[150]\ttrain-mlogloss:0.581122\tvalid-mlogloss:0.980457\n",
      "[200]\ttrain-mlogloss:0.471949\tvalid-mlogloss:0.948235\n",
      "[250]\ttrain-mlogloss:0.389553\tvalid-mlogloss:0.931308\n",
      "[300]\ttrain-mlogloss:0.32323\tvalid-mlogloss:0.92412\n",
      "[350]\ttrain-mlogloss:0.272854\tvalid-mlogloss:0.923122\n",
      "[400]\ttrain-mlogloss:0.232535\tvalid-mlogloss:0.923399\n",
      "[450]\ttrain-mlogloss:0.197796\tvalid-mlogloss:0.926199\n",
      "Stopping. Best iteration:\n",
      "[365]\ttrain-mlogloss:0.260351\tvalid-mlogloss:0.922302\n",
      "\n",
      "0.922302211775\n",
      "[0]\ttrain-mlogloss:2.14362\tvalid-mlogloss:2.14338\n",
      "Multiple eval metrics have been passed: 'valid-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-mlogloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-mlogloss:1.09916\tvalid-mlogloss:1.18942\n",
      "[100]\ttrain-mlogloss:0.780761\tvalid-mlogloss:0.959605\n",
      "[150]\ttrain-mlogloss:0.607434\tvalid-mlogloss:0.871409\n",
      "[200]\ttrain-mlogloss:0.491526\tvalid-mlogloss:0.830039\n",
      "[250]\ttrain-mlogloss:0.406684\tvalid-mlogloss:0.808803\n",
      "[300]\ttrain-mlogloss:0.341684\tvalid-mlogloss:0.797797\n",
      "[350]\ttrain-mlogloss:0.289896\tvalid-mlogloss:0.79273\n",
      "[400]\ttrain-mlogloss:0.247517\tvalid-mlogloss:0.790891\n",
      "[450]\ttrain-mlogloss:0.213314\tvalid-mlogloss:0.790079\n",
      "[500]\ttrain-mlogloss:0.181945\tvalid-mlogloss:0.792618\n",
      "Stopping. Best iteration:\n",
      "[436]\ttrain-mlogloss:0.222582\tvalid-mlogloss:0.789541\n",
      "\n",
      "0.789540907043\n",
      "[0]\ttrain-mlogloss:2.14038\tvalid-mlogloss:2.15013\n",
      "Multiple eval metrics have been passed: 'valid-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-mlogloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-mlogloss:1.06489\tvalid-mlogloss:1.26992\n",
      "[100]\ttrain-mlogloss:0.752975\tvalid-mlogloss:1.06624\n",
      "[150]\ttrain-mlogloss:0.586268\tvalid-mlogloss:0.991425\n",
      "[200]\ttrain-mlogloss:0.471963\tvalid-mlogloss:0.958395\n",
      "[250]\ttrain-mlogloss:0.386573\tvalid-mlogloss:0.946426\n",
      "[300]\ttrain-mlogloss:0.321795\tvalid-mlogloss:0.942317\n",
      "[350]\ttrain-mlogloss:0.269002\tvalid-mlogloss:0.942272\n",
      "[400]\ttrain-mlogloss:0.227438\tvalid-mlogloss:0.944656\n",
      "Stopping. Best iteration:\n",
      "[314]\ttrain-mlogloss:0.305702\tvalid-mlogloss:0.94053\n",
      "\n",
      "0.940530447591\n"
     ]
    }
   ],
   "source": [
    "y = y - 1 #fix for zero bound array\n",
    "\n",
    "denom = 0\n",
    "fold = 10 #Change to 5, 1 for Kaggle Limits\n",
    "for i in range(fold):\n",
    "    params = {\n",
    "        'eta': 0.03333,\n",
    "        'max_depth': 4,\n",
    "        'objective': 'multi:softprob',\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'num_class': 9,\n",
    "        'seed': i,\n",
    "        'silent': True\n",
    "    }\n",
    "    x1, x2, y1, y2 = model_selection.train_test_split(train, y, test_size=0.18, random_state=i)\n",
    "    watchlist = [(xgb.DMatrix(x1, y1), 'train'), (xgb.DMatrix(x2, y2), 'valid')]\n",
    "    model = xgb.train(params, xgb.DMatrix(x1, y1), 1000,  watchlist, verbose_eval=50, early_stopping_rounds=100)\n",
    "    score1 = metrics.log_loss(y2, model.predict(xgb.DMatrix(x2), ntree_limit=model.best_ntree_limit), labels = list(range(9)))\n",
    "    print(score1)\n",
    "    #if score < 0.9:\n",
    "    if denom != 0:\n",
    "        pred = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit+80)\n",
    "        preds += pred\n",
    "    else:\n",
    "        pred = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit+80)\n",
    "        preds = pred.copy()\n",
    "    denom += 1\n",
    "    submission = pd.DataFrame(pred, columns=['class'+str(c+1) for c in range(9)])\n",
    "    submission['ID'] = pid\n",
    "    submission.to_csv('../submissions/submission3_xgb_fold_'  + str(i) + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds /= denom\n",
    "submission = pd.DataFrame(preds, columns=['class'+str(c+1) for c in range(9)])\n",
    "submission['ID'] = pid\n",
    "submission.to_csv('../submissions/submission3_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Text</th>\n",
       "      <th>Gene_Share</th>\n",
       "      <th>Variation_Share</th>\n",
       "      <th>Gene_0</th>\n",
       "      <th>Variation0</th>\n",
       "      <th>Gene_1</th>\n",
       "      <th>Variation1</th>\n",
       "      <th>...</th>\n",
       "      <th>GV_YAP1</th>\n",
       "      <th>GV_p61BRAF</th>\n",
       "      <th>Gene_lbl_enc</th>\n",
       "      <th>Gene_len</th>\n",
       "      <th>Gene_words</th>\n",
       "      <th>Variation_lbl_enc</th>\n",
       "      <th>Variation_len</th>\n",
       "      <th>Variation_words</th>\n",
       "      <th>Text_len</th>\n",
       "      <th>Text_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FAM58A</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>Cyclin-dependent kinases (CDKs) regulate a var...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>447</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7654</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>39672</td>\n",
       "      <td>6105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CBL</td>\n",
       "      <td>W802*</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8255</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>36691</td>\n",
       "      <td>5783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBL</td>\n",
       "      <td>Q249E</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5191</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>36691</td>\n",
       "      <td>5783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CBL</td>\n",
       "      <td>N454D</td>\n",
       "      <td>Recent evidence has demonstrated that acquired...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4572</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>36238</td>\n",
       "      <td>5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CBL</td>\n",
       "      <td>L399V</td>\n",
       "      <td>Oncogenic mutations in the monomeric Casitas B...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3958</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>41308</td>\n",
       "      <td>6248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID    Gene             Variation  \\\n",
       "0   0  FAM58A  Truncating Mutations   \n",
       "1   1     CBL                 W802*   \n",
       "2   2     CBL                 Q249E   \n",
       "3   3     CBL                 N454D   \n",
       "4   4     CBL                 L399V   \n",
       "\n",
       "                                                Text  Gene_Share  \\\n",
       "0  Cyclin-dependent kinases (CDKs) regulate a var...           1   \n",
       "1   Abstract Background  Non-small cell lung canc...           1   \n",
       "2   Abstract Background  Non-small cell lung canc...           1   \n",
       "3  Recent evidence has demonstrated that acquired...           1   \n",
       "4  Oncogenic mutations in the monomeric Casitas B...           1   \n",
       "\n",
       "   Variation_Share  Gene_0  Variation0  Gene_1  Variation1     ...      \\\n",
       "0                1       5          24       9          40     ...       \n",
       "1                1       2          26      10           9     ...       \n",
       "2                1       2          21      10           3     ...       \n",
       "3                1       2          18      10           5     ...       \n",
       "4                1       2          16      10           4     ...       \n",
       "\n",
       "   GV_YAP1  GV_p61BRAF  Gene_lbl_enc  Gene_len  Gene_words  Variation_lbl_enc  \\\n",
       "0        0           0           447         6           1               7654   \n",
       "1        0           0           216         3           1               8255   \n",
       "2        0           0           216         3           1               5191   \n",
       "3        0           0           216         3           1               4572   \n",
       "4        0           0           216         3           1               3958   \n",
       "\n",
       "   Variation_len  Variation_words  Text_len  Text_words  \n",
       "0             20                2     39672        6105  \n",
       "1              5                1     36691        5783  \n",
       "2              5                1     36691        5783  \n",
       "3              5                1     36238        5625  \n",
       "4              5                1     41308        6248  \n",
       "\n",
       "[5 rows x 3217 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds8 = pd.read_csv('../submissions/submission3_xgb_fold_8.csv',index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>class3</th>\n",
       "      <th>class4</th>\n",
       "      <th>class5</th>\n",
       "      <th>class6</th>\n",
       "      <th>class7</th>\n",
       "      <th>class8</th>\n",
       "      <th>class9</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007239</td>\n",
       "      <td>0.146908</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.041419</td>\n",
       "      <td>0.030657</td>\n",
       "      <td>0.006896</td>\n",
       "      <td>0.764701</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.211131</td>\n",
       "      <td>0.070594</td>\n",
       "      <td>0.010737</td>\n",
       "      <td>0.324733</td>\n",
       "      <td>0.044138</td>\n",
       "      <td>0.035876</td>\n",
       "      <td>0.300727</td>\n",
       "      <td>0.001553</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085789</td>\n",
       "      <td>0.165576</td>\n",
       "      <td>0.013220</td>\n",
       "      <td>0.233871</td>\n",
       "      <td>0.101858</td>\n",
       "      <td>0.007711</td>\n",
       "      <td>0.390293</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.087091</td>\n",
       "      <td>0.133717</td>\n",
       "      <td>0.005466</td>\n",
       "      <td>0.018277</td>\n",
       "      <td>0.011644</td>\n",
       "      <td>0.030799</td>\n",
       "      <td>0.711946</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.063124</td>\n",
       "      <td>0.132109</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.381073</td>\n",
       "      <td>0.016120</td>\n",
       "      <td>0.019998</td>\n",
       "      <td>0.378083</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>0.002505</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     class1    class2    class3    class4    class5    class6    class7  \\\n",
       "0  0.007239  0.146908  0.001316  0.041419  0.030657  0.006896  0.764701   \n",
       "1  0.211131  0.070594  0.010737  0.324733  0.044138  0.035876  0.300727   \n",
       "2  0.085789  0.165576  0.013220  0.233871  0.101858  0.007711  0.390293   \n",
       "3  0.087091  0.133717  0.005466  0.018277  0.011644  0.030799  0.711946   \n",
       "4  0.063124  0.132109  0.004393  0.381073  0.016120  0.019998  0.378083   \n",
       "\n",
       "     class8    class9  ID  \n",
       "0  0.000639  0.000224   0  \n",
       "1  0.001553  0.000510   1  \n",
       "2  0.001293  0.000389   2  \n",
       "3  0.000477  0.000583   3  \n",
       "4  0.002593  0.002505   4  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds8.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds8 = df_preds8.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds8['class'] = df_preds8.idxmax(axis=1)\n",
    "df_preds8['class'] = df_preds8['class'].str[-1].astype(int)\n",
    "df_preds8['class'] = df_preds8['class'] -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>class3</th>\n",
       "      <th>class4</th>\n",
       "      <th>class5</th>\n",
       "      <th>class6</th>\n",
       "      <th>class7</th>\n",
       "      <th>class8</th>\n",
       "      <th>class9</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007239</td>\n",
       "      <td>0.146908</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.041419</td>\n",
       "      <td>0.030657</td>\n",
       "      <td>0.006896</td>\n",
       "      <td>0.764701</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.211131</td>\n",
       "      <td>0.070594</td>\n",
       "      <td>0.010737</td>\n",
       "      <td>0.324733</td>\n",
       "      <td>0.044138</td>\n",
       "      <td>0.035876</td>\n",
       "      <td>0.300727</td>\n",
       "      <td>0.001553</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085789</td>\n",
       "      <td>0.165576</td>\n",
       "      <td>0.013220</td>\n",
       "      <td>0.233871</td>\n",
       "      <td>0.101858</td>\n",
       "      <td>0.007711</td>\n",
       "      <td>0.390293</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.087091</td>\n",
       "      <td>0.133717</td>\n",
       "      <td>0.005466</td>\n",
       "      <td>0.018277</td>\n",
       "      <td>0.011644</td>\n",
       "      <td>0.030799</td>\n",
       "      <td>0.711946</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.063124</td>\n",
       "      <td>0.132109</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.381073</td>\n",
       "      <td>0.016120</td>\n",
       "      <td>0.019998</td>\n",
       "      <td>0.378083</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>0.002505</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     class1    class2    class3    class4    class5    class6    class7  \\\n",
       "0  0.007239  0.146908  0.001316  0.041419  0.030657  0.006896  0.764701   \n",
       "1  0.211131  0.070594  0.010737  0.324733  0.044138  0.035876  0.300727   \n",
       "2  0.085789  0.165576  0.013220  0.233871  0.101858  0.007711  0.390293   \n",
       "3  0.087091  0.133717  0.005466  0.018277  0.011644  0.030799  0.711946   \n",
       "4  0.063124  0.132109  0.004393  0.381073  0.016120  0.019998  0.378083   \n",
       "\n",
       "     class8    class9  class  \n",
       "0  0.000639  0.000224      6  \n",
       "1  0.001553  0.000510      3  \n",
       "2  0.001293  0.000389      6  \n",
       "3  0.000477  0.000583      6  \n",
       "4  0.002593  0.002505      3  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds8.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n"
     ]
    }
   ],
   "source": [
    "print(df_preds8['class'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds8 = df_preds8.drop(['class1','class2','class3','class4','class5','class6','class7','class8','class9'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_preds8.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class\n",
       "0      6\n",
       "1      3\n",
       "2      6\n",
       "3      6\n",
       "4      3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds8.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pseudo = df_preds8['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.concatenate((y, y_pseudo), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((train, test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "denom = 0\n",
    "fold = 10 #Change to 5, 1 for Kaggle Limits\n",
    "for i in range(fold):\n",
    "    params = {\n",
    "        'eta': 0.03333,\n",
    "        'max_depth': 4,\n",
    "        'objective': 'multi:softprob',\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'num_class': 9,\n",
    "        'seed': i,\n",
    "        'silent': True\n",
    "    }\n",
    "    x1, x2, y1, y2 = model_selection.train_test_split(X, Y, test_size=0.18, random_state=i)\n",
    "    watchlist = [(xgb.DMatrix(x1, y1), 'train'), (xgb.DMatrix(x2, y2), 'valid')]\n",
    "    model = xgb.train(params, xgb.DMatrix(x1, y1), 1000,  watchlist, verbose_eval=50, early_stopping_rounds=100)\n",
    "    score1 = metrics.log_loss(y2, model.predict(xgb.DMatrix(x2), ntree_limit=model.best_ntree_limit), labels = list(range(9)))\n",
    "    print(score1)\n",
    "    #if score < 0.9:\n",
    "    if denom != 0:\n",
    "        pred = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit+80)\n",
    "        preds += pred\n",
    "    else:\n",
    "        pred = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit+80)\n",
    "        preds = pred.copy()\n",
    "    denom += 1\n",
    "    submission = pd.DataFrame(pred, columns=['class'+str(c+1) for c in range(9)])\n",
    "    submission['ID'] = pid\n",
    "    submission.to_csv('../submissions/submission31_xgb_fold_'  + str(i) + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tr = te.drop('class',axis=1)\n",
    "#tr = te.drop('Class',axis=1)\n",
    "te = te.drop('class',axis=1)\n",
    "#te = te.drop('Class',axis=1)\n",
    "te.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = tr\n",
    "df0['Class'] = pd.to_numeric(y,errors='coerce').astype(int)\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_preds8.to_csv('../submissions/my_preds8.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "te.to_csv('../submissions/my_te.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "te1 = pd.read_csv('../submissions/my_te1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df1 = te\n",
    "#df_preds8 = df_preds8[pd.to_numeric(df_preds8.my1, errors='coerce').notnull()]\n",
    "#df_preds8['my1'] = pd.to_numeric(df_preds8.my1,errors='coerce').astype(int)\n",
    "#df1.head()\n",
    "print(te.shape)\n",
    "print(df_preds8.shape)\n",
    "print(df_preds8.head())\n",
    "#print(df_preds8.isnull().sum())\n",
    "df1=te\n",
    "df1['Class'] = df_preds8['class']\n",
    "#print(df1.isnull().sum())\n",
    "#df1['class'] = df1['class'].astype(int)\n",
    "print(df_preds8['class'].dtype)\n",
    "print(df1['Class'].dtype)\n",
    "print(df1.shape)\n",
    "#df = pd.concat([df0,df1])\n",
    "#df2 = df\n",
    "    \n",
    "# index = df['class'].index[df['class'].apply(np.isnan)]\n",
    "# df_index = df.index.values.tolist()\n",
    "# [df_index.index(i) for i in index]\n",
    "#df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pipeline...')\n",
    "train = df0\n",
    "test = te1\n",
    "\n",
    "# fp = pipeline.Pipeline([\n",
    "#     ('union', pipeline.FeatureUnion(\n",
    "#         n_jobs = -1,\n",
    "#         transformer_list = [\n",
    "#             ('standard', cust_regression_vals()),\n",
    "#             ('pi1', pipeline.Pipeline([('Gene', cust_txt_col('Gene')), \n",
    "#                                        ('count_Gene', feature_extraction.text.CountVectorizer(analyzer=u'char', ngram_range=(1, 8))), \n",
    "#                                        ('tsvd1', decomposition.TruncatedSVD(n_components=20, n_iter=25, random_state=12))])),\n",
    "#             ('pi2', pipeline.Pipeline([('Variation', cust_txt_col('Variation')), \n",
    "#                                        ('count_Variation', feature_extraction.text.CountVectorizer(analyzer=u'char', ngram_range=(1, 8))), \n",
    "#                                        ('tsvd2', decomposition.TruncatedSVD(n_components=20, n_iter=25, random_state=12))])),\n",
    "#             #commented for Kaggle Limits\n",
    "#             ('pi3', pipeline.Pipeline([('Text', cust_txt_col('Text')), \n",
    "#                                        ('hv', feature_extraction.text.HashingVectorizer(decode_error='ignore', n_features=2 ** 16, non_negative=True, ngram_range=(1, 3))),\n",
    "#                                        ('tfidf_Text', feature_extraction.text.TfidfTransformer()), \n",
    "#                                        ('tsvd3', decomposition.TruncatedSVD(n_components=300, n_iter=25, random_state=12))]))\n",
    "\n",
    "        \n",
    "#         ])\n",
    "#     )])\n",
    "\n",
    "# tr1 = train\n",
    "# te1 = test\n",
    "\n",
    "train = fp.fit_transform(train)\n",
    "print (train.shape)\n",
    "\n",
    "test_t = np.empty([0, train.shape[1]])\n",
    "step = 200\n",
    "for i in range(0, len(test), step):\n",
    "    step_end = i+step\n",
    "    step_end = step_end if step_end < len(test) else len(test)\n",
    "    _test = fp.transform(test.iloc[i:step_end])\n",
    "    test_t = np.vstack((test_t, _test))\n",
    "test = test_t\n",
    "print (test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1=te1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df0,df1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df\n",
    "Y_train = df['Class']\n",
    "T_train_xgb = xgb.DMatrix(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "        'eta': 0.03333,\n",
    "        'max_depth': 4,\n",
    "        'objective': 'multi:softprob',\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'num_class': 9,\n",
    "        'seed': i,\n",
    "        'silent': True\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.cv(params = params, dtrain = T_train_xgb, num_boost_round = 3000, nfold = 10,\n",
    "                metrics = ['mlogloss'], # Make sure you enter metrics inside a list or you may encounter issues!\n",
    "                early_stopping_rounds = 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
