{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import feather\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "  \n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "  \n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.utils.testing import assert_array_equal\n",
    "from sklearn.utils.testing import assert_equal\n",
    "from sklearn.utils.testing import assert_almost_equal\n",
    "from sklearn.utils.testing import assert_true\n",
    "from sklearn.utils.testing import assert_false\n",
    "from sklearn.utils.testing import assert_raises\n",
    "  \n",
    "from sklearn.utils.testing import assert_greater\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import log_loss, confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from utils import multi_log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def save_classifier(fname, clf):\n",
    "    # save the classifier\n",
    "    with open(fname, 'wb') as fid:\n",
    "        pickle.dump(clf, fid)\n",
    "\n",
    "def load_classifier(fname):\n",
    "    # load it again\n",
    "    with open(fname, 'rb') as fid:\n",
    "        clf = pickle.load(fid)\n",
    "        return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = np.load('../cache/train_p_stage1_fe2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = np.load('../cache/test_p_stage1_fe2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../cache/stage1_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y\n",
       "0  1\n",
       "1  2\n",
       "2  2\n",
       "3  3\n",
       "4  4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3321, 10233)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../cache/stage1_p_test_labels.csv')\n",
    "test_labels = df1['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 4.846830985915493, 2: 6.347345132743363, 3: 36.31460674157304, 4: 3.8411078717201166, 5: 12.723140495867769, 6: 11.076363636363636, 7: 2.484784889821616, 8: 173.78947368421052, 9: 88.75675675675676}\n"
     ]
    }
   ],
   "source": [
    "wts_per_class = np.load('../cache/stage1_train_weights_per_class.npy')\n",
    "wts_per_class = wts_per_class.tolist()\n",
    "print(wts_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    953\n",
       "4    686\n",
       "1    568\n",
       "2    452\n",
       "6    275\n",
       "5    242\n",
       "3     89\n",
       "9     37\n",
       "8     19\n",
       "dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15903694882083882"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * (953/3321) * 0.11/ ((953/3321) + 0.11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    101\n",
       "1     94\n",
       "4     65\n",
       "2     46\n",
       "5     25\n",
       "6     22\n",
       "3      7\n",
       "9      6\n",
       "8      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(368, 10233)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15705400056545096"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * (101/368) * 0.11/ ((101/368) + 0.11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def test_ovo_gridsearch():\n",
    "ovo = OneVsOneClassifier(svm.SVC(probability=True))\n",
    "Cs = [0.01, 0.02, 0.05, 0.09]\n",
    "cv = GridSearchCV(ovo, {'estimator__C': Cs})\n",
    "cv.fit(df_train, y)\n",
    "best_C = cv.best_estimator_.estimators_[0].C\n",
    "assert_true(best_C in Cs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n"
     ]
    }
   ],
   "source": [
    "print(best_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovo = CalibratedClassifierCV(OneVsOneClassifier(svm.SVC(probability=True, C=0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalibratedClassifierCV(base_estimator=OneVsOneClassifier(estimator=SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "          n_jobs=1),\n",
       "            cv=3, method='sigmoid')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo.fit(df_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_p = ovo.predict_proba(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = test_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage1 partial multi_log_loss: 1.8186399268986517\n",
      "stage1 partial f1_score: 0.27445652173913043\n",
      "stage1 partial accuracy: 0.27445652173913043\n",
      "[[  0   0   0   0   0   0  94   0   0]\n",
      " [  0   0   0   0   0   0  46   0   0]\n",
      " [  0   0   0   0   0   0   7   0   0]\n",
      " [  0   0   0   0   0   0  65   0   0]\n",
      " [  0   0   0   0   0   0  25   0   0]\n",
      " [  0   0   0   0   0   0  22   0   0]\n",
      " [  0   0   0   0   0   0 101   0   0]\n",
      " [  0   0   0   0   0   0   2   0   0]\n",
      " [  0   0   0   0   0   0   6   0   0]]\n"
     ]
    }
   ],
   "source": [
    "score2 = log_loss(test_labels, test_preds, labels = range(1,10))\n",
    "print('stage1 partial multi_log_loss: {}'.format(score2))\n",
    "\n",
    "fscore = f1_score(test_labels, test_preds.argmax(axis=1)+1, labels = list(range(1,10)), average='micro')\n",
    "print('stage1 partial f1_score: {}'.format(fscore))\n",
    "\n",
    "acc = accuracy_score(test_labels, test_preds.argmax(axis=1)+1)\n",
    "print('stage1 partial accuracy: {}'.format(acc))\n",
    "\n",
    "print(confusion_matrix(test_labels, test_preds.argmax(axis=1)+1, labels = list(range(1,10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['y'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(CalibratedClassifierCV(LinearSVC())).fit(df_train, df['y'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = clf.predict_proba(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.19963798  0.12434148  0.02703923 ...,  0.27170648  0.00627771\n",
      "   0.0106242 ]\n",
      " [ 0.19012832  0.1268235   0.04303355 ...,  0.22421147  0.00585256\n",
      "   0.01101572]\n",
      " [ 0.14800983  0.14545672  0.03859867 ...,  0.27126375  0.00573652\n",
      "   0.0078683 ]\n",
      " ..., \n",
      " [ 0.16209228  0.13924399  0.0353278  ...,  0.27202533  0.00589397\n",
      "   0.00867665]\n",
      " [ 0.14869046  0.14712454  0.0173737  ...,  0.33439177  0.00563372\n",
      "   0.00930825]\n",
      " [ 0.17616286  0.13069378  0.03403332 ...,  0.2665317   0.0061262\n",
      "   0.00940196]]\n"
     ]
    }
   ],
   "source": [
    "print(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage1 partial multi_log_loss: 1.7874586410646618\n",
      "stage1 partial f1_score: 0.28804347826086957\n",
      "stage1 partial accuracy: 0.28804347826086957\n",
      "[[ 0  0  0  5  0  0 89  0  0]\n",
      " [ 0  0  0  1  0  0 45  0  0]\n",
      " [ 0  0  0  1  0  0  6  0  0]\n",
      " [ 0  0  0  7  0  0 58  0  0]\n",
      " [ 0  0  0  2  0  0 23  0  0]\n",
      " [ 0  0  0  2  0  0 20  0  0]\n",
      " [ 0  0  0  2  0  0 99  0  0]\n",
      " [ 0  0  0  0  0  0  2  0  0]\n",
      " [ 0  0  0  1  0  0  5  0  0]]\n"
     ]
    }
   ],
   "source": [
    "score2 = log_loss(test_labels, test_preds, labels=[1,2,3,4,5,6,7,8,9])\n",
    "print('stage1 partial multi_log_loss: {}'.format(score2))\n",
    "\n",
    "fscore = f1_score(test_labels, test_preds.argmax(axis=1)+1, labels = list(range(1,10)), average='micro')\n",
    "print('stage1 partial f1_score: {}'.format(fscore))\n",
    "\n",
    "acc = accuracy_score(test_labels, test_preds.argmax(axis=1)+1)\n",
    "print('stage1 partial accuracy: {}'.format(acc))\n",
    "\n",
    "print(confusion_matrix(test_labels, test_preds.argmax(axis=1)+1, labels = list(range(1,10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = df['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovo = MultinomialNB()\n",
    "Y_pred =ovo.fit(abs(df_train), Y).predict_proba(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = Y_pred.clip(min=0.05, max=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage1 partial multi_log_loss: 2.9597867651212026\n",
      "stage1 partial f1_score: 0.11413043478260869\n",
      "stage1 partial accuracy: 0.11413043478260869\n",
      "[[ 9  0 23  6  0 19  3  9 25]\n",
      " [ 1  4 15  0  2 11  5  0  8]\n",
      " [ 2  0  4  0  0  0  0  0  1]\n",
      " [ 3  1 26  5  0  4  2  2 22]\n",
      " [ 2  0 10  0  2  8  2  0  1]\n",
      " [ 1  0  7  0  0  5  1  1  7]\n",
      " [ 1  6 19  1  5 14 10  6 39]\n",
      " [ 0  0  0  0  0  0  0  0  2]\n",
      " [ 0  0  3  0  0  0  0  0  3]]\n"
     ]
    }
   ],
   "source": [
    "score2 = log_loss(test_labels, Y_pred, labels=range(1,10))\n",
    "print('stage1 partial multi_log_loss: {}'.format(score2))\n",
    "\n",
    "fscore = f1_score(test_labels, Y_pred.argmax(axis=1)+1, labels = list(range(1,10)), average='micro')\n",
    "print('stage1 partial f1_score: {}'.format(fscore))\n",
    "\n",
    "acc = accuracy_score(test_labels, Y_pred.argmax(axis=1)+1)\n",
    "print('stage1 partial accuracy: {}'.format(acc))\n",
    "\n",
    "print(confusion_matrix(test_labels, Y_pred.argmax(axis=1)+1, labels = list(range(1,10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
