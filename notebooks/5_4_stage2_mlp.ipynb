{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import log_loss, confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from utils import *\n",
    "\n",
    "from sklearn.metrics import log_loss, confusion_matrix, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 4.572507552870091, 2: 6.407630522088353, 3: 37.427083333333336, 4: 3.912117177097204, 5: 12.816479400749063, 6: 11.42087542087542, 7: 2.5, 8: 174.66666666666666, 9: 84.79069767441861}\n"
     ]
    }
   ],
   "source": [
    "df_train = np.load('../cache/train_stage2_fe2.npy')\n",
    "df_test = np.load('../cache/test_stage2_fe2.npy')\n",
    "df = pd.read_csv('../cache/stage2_labels.csv')\n",
    "y = df['y'].values\n",
    "\n",
    "df = pd.read_csv('../cache/stage2_test_id.csv')\n",
    "pid = df.ID.values\n",
    "\n",
    "wts_per_class = np.load('../cache/stage2_train_weights_per_class.npy')\n",
    "wts_per_class = wts_per_class.tolist()\n",
    "print(wts_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = y-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wts_per_class2 = {}\n",
    "wts_per_class2 = {i:wts_per_class[i+1] for i in y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = np.array([wts_per_class[j+1] for j in y], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp_model = MLPClassifier()\n",
    "\n",
    "# MLPClassifier(hidden_layer_sizes=(100, ), activation=’relu’, solver=’adam’, alpha=0.0001, \n",
    "#               batch_size=’auto’, learning_rate=’constant’, learning_rate_init=0.001, \n",
    "#               power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, \n",
    "#               verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n",
    "#               early_stopping=False, validation_fraction=0.1,\n",
    "#               beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "parameters = {\n",
    "    'solver': ['adam', 'sgd'], \n",
    "    'max_iter': [50,250,500],\n",
    "    'learning_rate_init': [0.001, 0.0001, 0.01, 0.1],\n",
    "    'alpha': [0.001],\n",
    "    'power_t': [0.1],\n",
    "    'random_state': [1337],\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(mlp_model, parameters, n_jobs=4, \n",
    "                   cv=StratifiedKFold(y, 5, True),\n",
    "                   scoring = 'neg_log_loss',\n",
    "                   verbose=2, refit=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV] alpha=0.001, learning_rate_init=0.001, max_iter=50, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV] alpha=0.001, learning_rate_init=0.001, max_iter=50, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV] alpha=0.001, learning_rate_init=0.001, max_iter=50, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV] alpha=0.001, learning_rate_init=0.001, max_iter=50, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.001, max_iter=50, power_t=0.1, random_state=1337, solver=adam, total=   5.8s\n",
      "[CV] alpha=0.001, learning_rate_init=0.001, max_iter=50, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.001, max_iter=50, power_t=0.1, random_state=1337, solver=adam, total=   9.1s\n",
      "[CV] alpha=0.001, learning_rate_init=0.001, max_iter=50, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.001, max_iter=50, power_t=0.1, random_state=1337, solver=adam, total=  10.1s\n",
      "[CV] alpha=0.001, learning_rate_init=0.001, max_iter=50, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.001, max_iter=50, power_t=0.1, random_state=1337, solver=adam, total=  12.5s\n",
      "[CV] alpha=0.001, learning_rate_init=0.001, max_iter=50, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.001, max_iter=50, power_t=0.1, random_state=1337, solver=sgd, total=   4.5s\n",
      "[CV] alpha=0.001, learning_rate_init=0.001, max_iter=50, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.001, max_iter=50, power_t=0.1, random_state=1337, solver=adam, total=   8.5s\n",
      "[CV] alpha=0.001, learning_rate_init=0.001, max_iter=50, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.001, max_iter=50, power_t=0.1, random_state=1337, solver=sgd, total=   4.5s\n",
      "[CV] alpha=0.001, learning_rate_init=0.001, max_iter=250, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.001, max_iter=50, power_t=0.1, random_state=1337, solver=sgd, total=   4.7s\n",
      "[CV] alpha=0.001, learning_rate_init=0.001, max_iter=250, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.001, max_iter=50, power_t=0.1, random_state=1337, solver=sgd, total=   3.6s\n",
      "[CV] alpha=0.001, learning_rate_init=0.001, max_iter=250, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.001, max_iter=50, power_t=0.1, random_state=1337, solver=sgd, total=   5.4s\n",
      "[CV] alpha=0.001, learning_rate_init=0.001, max_iter=250, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.001, max_iter=250, power_t=0.1, random_state=1337, solver=adam, total=   6.5s\n",
      "[CV] alpha=0.001, learning_rate_init=0.001, max_iter=250, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.001, max_iter=250, power_t=0.1, random_state=1337, solver=adam, total=   8.9s\n",
      "[CV] alpha=0.001, learning_rate_init=0.001, max_iter=250, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.001, max_iter=250, power_t=0.1, random_state=1337, solver=adam, total=  10.9s\n",
      "[CV] alpha=0.001, learning_rate_init=0.001, max_iter=250, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.001, max_iter=250, power_t=0.1, random_state=1337, solver=adam, total=   8.7s\n",
      "[CV] alpha=0.001, learning_rate_init=0.001, max_iter=250, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.001, max_iter=250, power_t=0.1, random_state=1337, solver=adam, total=  13.6s\n",
      "[CV] alpha=0.001, learning_rate_init=0.001, max_iter=250, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.001, max_iter=250, power_t=0.1, random_state=1337, solver=sgd, total=   4.5s\n",
      "[CV] alpha=0.001, learning_rate_init=0.001, max_iter=250, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.001, max_iter=250, power_t=0.1, random_state=1337, solver=sgd, total=   4.1s\n",
      "[CV] alpha=0.001, learning_rate_init=0.001, max_iter=500, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.001, max_iter=250, power_t=0.1, random_state=1337, solver=sgd, total=   4.3s\n",
      "[CV] alpha=0.001, learning_rate_init=0.001, max_iter=500, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.001, max_iter=250, power_t=0.1, random_state=1337, solver=sgd, total=   4.5s\n",
      "[CV] alpha=0.001, learning_rate_init=0.001, max_iter=500, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.001, max_iter=250, power_t=0.1, random_state=1337, solver=sgd, total=   4.8s\n",
      "[CV] alpha=0.001, learning_rate_init=0.001, max_iter=500, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.001, max_iter=500, power_t=0.1, random_state=1337, solver=adam, total=   6.7s\n",
      "[CV] alpha=0.001, learning_rate_init=0.001, max_iter=500, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.001, max_iter=500, power_t=0.1, random_state=1337, solver=adam, total=   8.6s\n",
      "[CV] alpha=0.001, learning_rate_init=0.001, max_iter=500, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.001, max_iter=500, power_t=0.1, random_state=1337, solver=adam, total=  11.2s\n",
      "[CV] alpha=0.001, learning_rate_init=0.001, max_iter=500, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.001, max_iter=500, power_t=0.1, random_state=1337, solver=sgd, total=   4.2s\n",
      "[CV] alpha=0.001, learning_rate_init=0.001, max_iter=500, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.001, max_iter=500, power_t=0.1, random_state=1337, solver=adam, total=  14.1s\n",
      "[CV] alpha=0.001, learning_rate_init=0.001, max_iter=500, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.001, max_iter=500, power_t=0.1, random_state=1337, solver=adam, total=   9.4s\n",
      "[CV] alpha=0.001, learning_rate_init=0.001, max_iter=500, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.001, max_iter=500, power_t=0.1, random_state=1337, solver=sgd, total=   4.4s\n",
      "[CV] alpha=0.001, learning_rate_init=0.0001, max_iter=50, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.001, max_iter=500, power_t=0.1, random_state=1337, solver=sgd, total=   4.3s\n",
      "[CV] alpha=0.001, learning_rate_init=0.0001, max_iter=50, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.001, max_iter=500, power_t=0.1, random_state=1337, solver=sgd, total=   4.3s\n",
      "[CV] alpha=0.001, learning_rate_init=0.0001, max_iter=50, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.001, max_iter=500, power_t=0.1, random_state=1337, solver=sgd, total=   4.1s\n",
      "[CV] alpha=0.001, learning_rate_init=0.0001, max_iter=50, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.0001, max_iter=50, power_t=0.1, random_state=1337, solver=adam, total=   4.8s\n",
      "[CV] alpha=0.001, learning_rate_init=0.0001, max_iter=50, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.0001, max_iter=50, power_t=0.1, random_state=1337, solver=adam, total=   5.0s\n",
      "[CV] alpha=0.001, learning_rate_init=0.0001, max_iter=50, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.0001, max_iter=50, power_t=0.1, random_state=1337, solver=adam, total=   5.2s\n",
      "[CV] alpha=0.001, learning_rate_init=0.0001, max_iter=50, power_t=0.1, random_state=1337, solver=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:  1.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.001, learning_rate_init=0.0001, max_iter=50, power_t=0.1, random_state=1337, solver=adam, total=   5.6s\n",
      "[CV] alpha=0.001, learning_rate_init=0.0001, max_iter=50, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.0001, max_iter=50, power_t=0.1, random_state=1337, solver=adam, total=   4.7s\n",
      "[CV] alpha=0.001, learning_rate_init=0.0001, max_iter=50, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.0001, max_iter=50, power_t=0.1, random_state=1337, solver=sgd, total=   4.1s\n",
      "[CV] alpha=0.001, learning_rate_init=0.0001, max_iter=50, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.0001, max_iter=50, power_t=0.1, random_state=1337, solver=sgd, total=   4.9s\n",
      "[CV] alpha=0.001, learning_rate_init=0.0001, max_iter=250, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.0001, max_iter=50, power_t=0.1, random_state=1337, solver=sgd, total=   4.5s\n",
      "[CV] alpha=0.001, learning_rate_init=0.0001, max_iter=250, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.0001, max_iter=50, power_t=0.1, random_state=1337, solver=sgd, total=   4.2s\n",
      "[CV] alpha=0.001, learning_rate_init=0.0001, max_iter=250, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.0001, max_iter=50, power_t=0.1, random_state=1337, solver=sgd, total=   4.2s\n",
      "[CV] alpha=0.001, learning_rate_init=0.0001, max_iter=250, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.0001, max_iter=250, power_t=0.1, random_state=1337, solver=adam, total=   4.8s\n",
      "[CV] alpha=0.001, learning_rate_init=0.0001, max_iter=250, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.0001, max_iter=250, power_t=0.1, random_state=1337, solver=adam, total=   4.6s\n",
      "[CV] alpha=0.001, learning_rate_init=0.0001, max_iter=250, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.0001, max_iter=250, power_t=0.1, random_state=1337, solver=adam, total=   4.7s\n",
      "[CV] alpha=0.001, learning_rate_init=0.0001, max_iter=250, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.0001, max_iter=250, power_t=0.1, random_state=1337, solver=adam, total=   5.3s\n",
      "[CV] alpha=0.001, learning_rate_init=0.0001, max_iter=250, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.0001, max_iter=250, power_t=0.1, random_state=1337, solver=adam, total=   5.1s\n",
      "[CV] alpha=0.001, learning_rate_init=0.0001, max_iter=250, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.0001, max_iter=250, power_t=0.1, random_state=1337, solver=sgd, total=   4.0s\n",
      "[CV] alpha=0.001, learning_rate_init=0.0001, max_iter=250, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.0001, max_iter=250, power_t=0.1, random_state=1337, solver=sgd, total=   4.1s\n",
      "[CV] alpha=0.001, learning_rate_init=0.0001, max_iter=500, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.0001, max_iter=250, power_t=0.1, random_state=1337, solver=sgd, total=   4.5s\n",
      "[CV] alpha=0.001, learning_rate_init=0.0001, max_iter=500, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.0001, max_iter=250, power_t=0.1, random_state=1337, solver=sgd, total=   4.5s\n",
      "[CV] alpha=0.001, learning_rate_init=0.0001, max_iter=500, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.0001, max_iter=250, power_t=0.1, random_state=1337, solver=sgd, total=   4.2s\n",
      "[CV] alpha=0.001, learning_rate_init=0.0001, max_iter=500, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.0001, max_iter=500, power_t=0.1, random_state=1337, solver=adam, total=   5.1s\n",
      "[CV] alpha=0.001, learning_rate_init=0.0001, max_iter=500, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.0001, max_iter=500, power_t=0.1, random_state=1337, solver=adam, total=   5.3s\n",
      "[CV] alpha=0.001, learning_rate_init=0.0001, max_iter=500, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.0001, max_iter=500, power_t=0.1, random_state=1337, solver=adam, total=   5.1s\n",
      "[CV] alpha=0.001, learning_rate_init=0.0001, max_iter=500, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.0001, max_iter=500, power_t=0.1, random_state=1337, solver=adam, total=   4.5s\n",
      "[CV] alpha=0.001, learning_rate_init=0.0001, max_iter=500, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.0001, max_iter=500, power_t=0.1, random_state=1337, solver=adam, total=   5.6s\n",
      "[CV] alpha=0.001, learning_rate_init=0.0001, max_iter=500, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.0001, max_iter=500, power_t=0.1, random_state=1337, solver=sgd, total=   4.0s\n",
      "[CV] alpha=0.001, learning_rate_init=0.0001, max_iter=500, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.0001, max_iter=500, power_t=0.1, random_state=1337, solver=sgd, total=   4.4s\n",
      "[CV] alpha=0.001, learning_rate_init=0.01, max_iter=50, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.0001, max_iter=500, power_t=0.1, random_state=1337, solver=sgd, total=   3.9s\n",
      "[CV] alpha=0.001, learning_rate_init=0.01, max_iter=50, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.0001, max_iter=500, power_t=0.1, random_state=1337, solver=sgd, total=   4.2s\n",
      "[CV] alpha=0.001, learning_rate_init=0.01, max_iter=50, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.0001, max_iter=500, power_t=0.1, random_state=1337, solver=sgd, total=   4.2s\n",
      "[CV] alpha=0.001, learning_rate_init=0.01, max_iter=50, power_t=0.1, random_state=1337, solver=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.001, learning_rate_init=0.01, max_iter=50, power_t=0.1, random_state=1337, solver=adam, total= 1.0min\n",
      "[CV] alpha=0.001, learning_rate_init=0.01, max_iter=50, power_t=0.1, random_state=1337, solver=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.001, learning_rate_init=0.01, max_iter=50, power_t=0.1, random_state=1337, solver=adam, total=  56.7s\n",
      "[CV] alpha=0.001, learning_rate_init=0.01, max_iter=50, power_t=0.1, random_state=1337, solver=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.001, learning_rate_init=0.01, max_iter=50, power_t=0.1, random_state=1337, solver=adam, total= 1.0min\n",
      "[CV] alpha=0.001, learning_rate_init=0.01, max_iter=50, power_t=0.1, random_state=1337, solver=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.001, learning_rate_init=0.01, max_iter=50, power_t=0.1, random_state=1337, solver=adam, total=  58.6s\n",
      "[CV] alpha=0.001, learning_rate_init=0.01, max_iter=50, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.01, max_iter=50, power_t=0.1, random_state=1337, solver=sgd, total=   4.5s\n",
      "[CV] alpha=0.001, learning_rate_init=0.01, max_iter=50, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.01, max_iter=50, power_t=0.1, random_state=1337, solver=sgd, total=   4.4s\n",
      "[CV] alpha=0.001, learning_rate_init=0.01, max_iter=50, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.01, max_iter=50, power_t=0.1, random_state=1337, solver=sgd, total=   4.4s\n",
      "[CV] alpha=0.001, learning_rate_init=0.01, max_iter=250, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.01, max_iter=50, power_t=0.1, random_state=1337, solver=sgd, total=   4.2s\n",
      "[CV] alpha=0.001, learning_rate_init=0.01, max_iter=250, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.01, max_iter=50, power_t=0.1, random_state=1337, solver=sgd, total=   4.0s\n",
      "[CV] alpha=0.001, learning_rate_init=0.01, max_iter=250, power_t=0.1, random_state=1337, solver=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.001, learning_rate_init=0.01, max_iter=50, power_t=0.1, random_state=1337, solver=adam, total=  58.0s\n",
      "[CV] alpha=0.001, learning_rate_init=0.01, max_iter=250, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.01, max_iter=250, power_t=0.1, random_state=1337, solver=adam, total= 1.1min\n",
      "[CV] alpha=0.001, learning_rate_init=0.01, max_iter=250, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.01, max_iter=250, power_t=0.1, random_state=1337, solver=adam, total= 1.1min\n",
      "[CV] alpha=0.001, learning_rate_init=0.01, max_iter=250, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.01, max_iter=250, power_t=0.1, random_state=1337, solver=sgd, total=   4.1s\n",
      "[CV] alpha=0.001, learning_rate_init=0.01, max_iter=250, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.01, max_iter=250, power_t=0.1, random_state=1337, solver=sgd, total=   4.0s\n",
      "[CV] alpha=0.001, learning_rate_init=0.01, max_iter=250, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.01, max_iter=250, power_t=0.1, random_state=1337, solver=sgd, total=   4.6s\n",
      "[CV] alpha=0.001, learning_rate_init=0.01, max_iter=250, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.01, max_iter=250, power_t=0.1, random_state=1337, solver=adam, total= 1.3min\n",
      "[CV] alpha=0.001, learning_rate_init=0.01, max_iter=250, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.01, max_iter=250, power_t=0.1, random_state=1337, solver=sgd, total=   4.6s\n",
      "[CV] alpha=0.001, learning_rate_init=0.01, max_iter=500, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.01, max_iter=250, power_t=0.1, random_state=1337, solver=sgd, total=   4.7s\n",
      "[CV] alpha=0.001, learning_rate_init=0.01, max_iter=500, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.01, max_iter=250, power_t=0.1, random_state=1337, solver=adam, total= 1.3min\n",
      "[CV] alpha=0.001, learning_rate_init=0.01, max_iter=500, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.01, max_iter=250, power_t=0.1, random_state=1337, solver=adam, total= 1.9min\n",
      "[CV] alpha=0.001, learning_rate_init=0.01, max_iter=500, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.01, max_iter=500, power_t=0.1, random_state=1337, solver=adam, total= 1.9min\n",
      "[CV] alpha=0.001, learning_rate_init=0.01, max_iter=500, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.01, max_iter=500, power_t=0.1, random_state=1337, solver=adam, total= 2.0min\n",
      "[CV] alpha=0.001, learning_rate_init=0.01, max_iter=500, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.01, max_iter=500, power_t=0.1, random_state=1337, solver=sgd, total=   6.3s\n",
      "[CV] alpha=0.001, learning_rate_init=0.01, max_iter=500, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.01, max_iter=500, power_t=0.1, random_state=1337, solver=sgd, total=   7.3s\n",
      "[CV] alpha=0.001, learning_rate_init=0.01, max_iter=500, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.01, max_iter=500, power_t=0.1, random_state=1337, solver=sgd, total=  13.8s\n",
      "[CV] alpha=0.001, learning_rate_init=0.01, max_iter=500, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.01, max_iter=500, power_t=0.1, random_state=1337, solver=sgd, total=  17.0s\n",
      "[CV] alpha=0.001, learning_rate_init=0.01, max_iter=500, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.01, max_iter=500, power_t=0.1, random_state=1337, solver=sgd, total=   6.9s\n",
      "[CV] alpha=0.001, learning_rate_init=0.1, max_iter=50, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.01, max_iter=500, power_t=0.1, random_state=1337, solver=adam, total= 2.7min\n",
      "[CV] alpha=0.001, learning_rate_init=0.1, max_iter=50, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.01, max_iter=500, power_t=0.1, random_state=1337, solver=adam, total= 2.3min\n",
      "[CV] alpha=0.001, learning_rate_init=0.1, max_iter=50, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.01, max_iter=500, power_t=0.1, random_state=1337, solver=adam, total= 2.3min\n",
      "[CV] alpha=0.001, learning_rate_init=0.1, max_iter=50, power_t=0.1, random_state=1337, solver=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.001, learning_rate_init=0.1, max_iter=50, power_t=0.1, random_state=1337, solver=adam, total= 2.0min\n",
      "[CV] alpha=0.001, learning_rate_init=0.1, max_iter=50, power_t=0.1, random_state=1337, solver=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.001, learning_rate_init=0.1, max_iter=50, power_t=0.1, random_state=1337, solver=adam, total= 2.1min\n",
      "[CV] alpha=0.001, learning_rate_init=0.1, max_iter=50, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.1, max_iter=50, power_t=0.1, random_state=1337, solver=sgd, total=   7.1s\n",
      "[CV] alpha=0.001, learning_rate_init=0.1, max_iter=50, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.1, max_iter=50, power_t=0.1, random_state=1337, solver=sgd, total=   6.9s\n",
      "[CV] alpha=0.001, learning_rate_init=0.1, max_iter=50, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.1, max_iter=50, power_t=0.1, random_state=1337, solver=sgd, total=   7.3s\n",
      "[CV] alpha=0.001, learning_rate_init=0.1, max_iter=50, power_t=0.1, random_state=1337, solver=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.001, learning_rate_init=0.1, max_iter=50, power_t=0.1, random_state=1337, solver=adam, total= 2.2min\n",
      "[CV] alpha=0.001, learning_rate_init=0.1, max_iter=50, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.1, max_iter=50, power_t=0.1, random_state=1337, solver=sgd, total=   6.3s\n",
      "[CV] alpha=0.001, learning_rate_init=0.1, max_iter=250, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.1, max_iter=50, power_t=0.1, random_state=1337, solver=sgd, total=   7.4s\n",
      "[CV] alpha=0.001, learning_rate_init=0.1, max_iter=250, power_t=0.1, random_state=1337, solver=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.001, learning_rate_init=0.1, max_iter=50, power_t=0.1, random_state=1337, solver=adam, total= 2.2min\n",
      "[CV] alpha=0.001, learning_rate_init=0.1, max_iter=250, power_t=0.1, random_state=1337, solver=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.001, learning_rate_init=0.1, max_iter=50, power_t=0.1, random_state=1337, solver=adam, total= 2.0min\n",
      "[CV] alpha=0.001, learning_rate_init=0.1, max_iter=250, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.1, max_iter=250, power_t=0.1, random_state=1337, solver=adam, total= 2.3min\n",
      "[CV] alpha=0.001, learning_rate_init=0.1, max_iter=250, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.1, max_iter=250, power_t=0.1, random_state=1337, solver=adam, total= 2.9min\n",
      "[CV] alpha=0.001, learning_rate_init=0.1, max_iter=250, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.1, max_iter=250, power_t=0.1, random_state=1337, solver=adam, total= 2.9min\n",
      "[CV] alpha=0.001, learning_rate_init=0.1, max_iter=250, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.1, max_iter=250, power_t=0.1, random_state=1337, solver=sgd, total=  10.4s\n",
      "[CV] alpha=0.001, learning_rate_init=0.1, max_iter=250, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.1, max_iter=250, power_t=0.1, random_state=1337, solver=sgd, total=  11.9s\n",
      "[CV] alpha=0.001, learning_rate_init=0.1, max_iter=250, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.1, max_iter=250, power_t=0.1, random_state=1337, solver=sgd, total=   7.2s\n",
      "[CV] alpha=0.001, learning_rate_init=0.1, max_iter=250, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.1, max_iter=250, power_t=0.1, random_state=1337, solver=sgd, total=   8.2s\n",
      "[CV] alpha=0.001, learning_rate_init=0.1, max_iter=500, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.1, max_iter=250, power_t=0.1, random_state=1337, solver=sgd, total=   8.2s\n",
      "[CV] alpha=0.001, learning_rate_init=0.1, max_iter=500, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.1, max_iter=250, power_t=0.1, random_state=1337, solver=adam, total= 2.7min\n",
      "[CV] alpha=0.001, learning_rate_init=0.1, max_iter=500, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.1, max_iter=250, power_t=0.1, random_state=1337, solver=adam, total= 3.4min\n",
      "[CV] alpha=0.001, learning_rate_init=0.1, max_iter=500, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.1, max_iter=500, power_t=0.1, random_state=1337, solver=adam, total= 2.6min\n",
      "[CV] alpha=0.001, learning_rate_init=0.1, max_iter=500, power_t=0.1, random_state=1337, solver=adam \n",
      "[CV]  alpha=0.001, learning_rate_init=0.1, max_iter=500, power_t=0.1, random_state=1337, solver=adam, total= 2.9min\n",
      "[CV] alpha=0.001, learning_rate_init=0.1, max_iter=500, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.1, max_iter=500, power_t=0.1, random_state=1337, solver=adam, total= 2.7min\n",
      "[CV] alpha=0.001, learning_rate_init=0.1, max_iter=500, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.1, max_iter=500, power_t=0.1, random_state=1337, solver=sgd, total=   6.0s\n",
      "[CV] alpha=0.001, learning_rate_init=0.1, max_iter=500, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.1, max_iter=500, power_t=0.1, random_state=1337, solver=sgd, total=  11.0s\n",
      "[CV] alpha=0.001, learning_rate_init=0.1, max_iter=500, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.1, max_iter=500, power_t=0.1, random_state=1337, solver=sgd, total=  10.4s\n",
      "[CV] alpha=0.001, learning_rate_init=0.1, max_iter=500, power_t=0.1, random_state=1337, solver=sgd \n",
      "[CV]  alpha=0.001, learning_rate_init=0.1, max_iter=500, power_t=0.1, random_state=1337, solver=sgd, total=   6.1s\n",
      "[CV]  alpha=0.001, learning_rate_init=0.1, max_iter=500, power_t=0.1, random_state=1337, solver=sgd, total=   8.1s\n",
      "[CV]  alpha=0.001, learning_rate_init=0.1, max_iter=500, power_t=0.1, random_state=1337, solver=adam, total= 3.0min\n",
      "[CV]  alpha=0.001, learning_rate_init=0.1, max_iter=500, power_t=0.1, random_state=1337, solver=adam, total= 3.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 120 out of 120 | elapsed: 19.4min finished\n",
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=sklearn.cross_validation.StratifiedKFold(labels=[0 1 ..., 3 0], n_folds=5, shuffle=True, random_state=None),\n",
       "       error_score='raise',\n",
       "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'solver': ['adam', 'sgd'], 'max_iter': [50, 250, 500], 'learning_rate_init': [0.001, 0.0001, 0.01, 0.1], 'alpha': [0.001], 'power_t': [0.1], 'random_state': [1337]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_log_loss', verbose=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(df_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.8296726568\n",
      "{'alpha': 0.001, 'learning_rate_init': 0.1, 'max_iter': 50, 'power_t': 0.1, 'random_state': 1337, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_score_)\n",
    "print(clf.best_params_)\n",
    "\n",
    "# -2.19642899615\n",
    "# {'alpha': 0.001, 'max_iter': 50, 'power_t': 0.1, 'random_state': 1337, 'solver': 'sgd'}\n",
    "\n",
    "# -1.82905221671\n",
    "# {'alpha': 0.001, 'learning_rate_init': 0.1, 'max_iter': 50, 'power_t': 0.1, 'random_state': 1337, \n",
    "#'solver': 'adam'}\n",
    "# 2.34559 on private LB, 1.91137 on public LB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.2030242   0.12867658  0.02765295 ...,  0.26141824  0.00517837\n",
      "   0.01145687]\n",
      " [ 0.2030242   0.12867658  0.02765295 ...,  0.26141824  0.00517837\n",
      "   0.01145687]\n",
      " [ 0.2030242   0.12867658  0.02765295 ...,  0.26141824  0.00517837\n",
      "   0.01145687]\n",
      " ..., \n",
      " [ 0.2030242   0.12867658  0.02765295 ...,  0.26141824  0.00517837\n",
      "   0.01145687]\n",
      " [ 0.2030242   0.12867658  0.02765295 ...,  0.26141824  0.00517837\n",
      "   0.01145687]\n",
      " [ 0.2030242   0.12867658  0.02765295 ...,  0.26141824  0.00517837\n",
      "   0.01145687]]\n"
     ]
    }
   ],
   "source": [
    "test_preds = clf.predict_proba(df_test)\n",
    "print(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_preds = test_preds.clip(min=0.05, max=0.95) # hack for kaggle since kaggle punishes severly if you predict \n",
    "# 1 and it is 0\n",
    "\n",
    "submission = pd.DataFrame(test_preds, columns=['class'+str(c+1) for c in range(9)])\n",
    "submission['ID'] = pid\n",
    "submission.to_csv('../submissions/sub_xgb_stage2_mlp.csv', index=False)\n",
    "# scores 2.34559 on stage2 private LB and 1.91137 on stage2 public LB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_classifier('../cache/stage2_mlp_clf.pkl', clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = np.load('../cache/train_stage2_x1.npy')\n",
    "x2 = np.load('../cache/train_stage2_x2.npy')\n",
    "y1 = np.load('../cache/train_stage2_y1.npy')\n",
    "y2 = np.load('../cache/train_stage2_y2.npy')\n",
    "\n",
    "# w1 = np.array([wts_per_class[j] for j in y1], )\n",
    "# w2 = np.array([wts_per_class[j] for j in y2], )\n",
    "\n",
    "w1 = np.load('../cache/stage2_train_weights_per_class.npy').tolist()\n",
    "w2 = np.load('../cache/stage2_train_weights_per_class.npy').tolist()\n",
    "\n",
    "w1_p = np.array([w1[j] for j in y1], )\n",
    "w2_p = np.array([w2[j] for j in y2], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_params_ = {'alpha': 0.001, 'learning_rate_init': 0.1, 'max_iter': 50, 'power_t': 0.1, \n",
    "                'random_state': 1337, 'solver': 'adam'}\n",
    "# clf1 = MLPClassifier(**clf.best_params_)\n",
    "\n",
    "clf1 = MLPClassifier(**best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y1 = y1-1\n",
    "y2 = y2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.1, max_iter=50, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.1, random_state=1337,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(x1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_preds = clf1.predict_proba(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_preds = test_preds.clip(min=0.05, max=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV multi_log_loss: 1.884022720626415\n",
      "CV f1_score: 0.12713710909501086\n",
      "CV accuracy: 0.2859078590785908\n",
      "[[  0   0   0   0   0   0 133   0   0]\n",
      " [  0   0   0   0   0   0 100   0   0]\n",
      " [  0   0   0   0   0   0  19   0   0]\n",
      " [  0   0   0   0   0   0 150   0   0]\n",
      " [  0   0   0   0   0   0  53   0   0]\n",
      " [  0   0   0   0   0   0  59   0   0]\n",
      " [  0   0   0   0   0   0 211   0   0]\n",
      " [  0   0   0   0   0   0   4   0   0]\n",
      " [  0   0   0   0   0   0   9   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda2/envs/aind-dog/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "score2 = log_loss(y2, test_preds, labels = list(range(9)))\n",
    "print('CV multi_log_loss: {}'.format(score2))\n",
    "\n",
    "fscore = f1_score(y2, test_preds.argmax(axis=1), labels = list(range(9)), average='weighted')\n",
    "print('CV f1_score: {}'.format(fscore))\n",
    "\n",
    "acc = accuracy_score(y2, test_preds.argmax(axis=1))\n",
    "print('CV accuracy: {}'.format(acc))\n",
    "\n",
    "print(confusion_matrix(y2, test_preds.argmax(axis=1), labels = list(range(9))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# score with stratified split\n",
    "# CV multi_log_loss: 1.884022720626415\n",
    "# CV f1_score: 0.12713710909501086\n",
    "# CV accuracy: 0.2859078590785908\n",
    "# [[  0   0   0   0   0   0 133   0   0]\n",
    "#  [  0   0   0   0   0   0 100   0   0]\n",
    "#  [  0   0   0   0   0   0  19   0   0]\n",
    "#  [  0   0   0   0   0   0 150   0   0]\n",
    "#  [  0   0   0   0   0   0  53   0   0]\n",
    "#  [  0   0   0   0   0   0  59   0   0]\n",
    "#  [  0   0   0   0   0   0 211   0   0]\n",
    "#  [  0   0   0   0   0   0   4   0   0]\n",
    "#  [  0   0   0   0   0   0   9   0   0]]\n",
    "\n",
    "# score before stratified split\n",
    "# CV multi_log_loss: 1.880231068515299\n",
    "# CV f1_score: 0.13801922169378109\n",
    "# CV accuracy: 0.2994579945799458\n",
    "# [[  0   0   0   0   0   0 129   0   0]\n",
    "#  [  0   0   0   0   0   0 106   0   0]\n",
    "#  [  0   0   0   0   0   0  24   0   0]\n",
    "#  [  0   0   0   0   0   0 141   0   0]\n",
    "#  [  0   0   0   0   0   0  54   0   0]\n",
    "#  [  0   0   0   0   0   0  55   0   0]\n",
    "#  [  0   0   0   0   0   0 221   0   0]\n",
    "#  [  0   0   0   0   0   0   2   0   0]\n",
    "#  [  0   0   0   0   0   0   6   0   0]]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
